# ğŸ§ª AI Medical Report Explainer

![Screenshot](https://media.discordapp.net/attachments/1397190732535697570/1397190781164326934/gif.gif?ex=6880d2d0&is=687f8150&hm=d4a2d90eb623f6b8aeb2a771c28e9c26d1ce9e2512d3173813b2467876ee4955&=&width=1600&height=868) 

An advanced AI-powered web application to automatically **analyze**, **explain**, and **diagnose** lab reports using OCR, Natural Language Processing (NLP), Named Entity Recognition (NER), and deep learning.

This tool allows patients and healthcare professionals to **upload lab reports (PDFs or images)** and receive:
- ğŸ§  Human-like explanations of medical terms and results
- ğŸ§¬ Intelligent lab value extraction (NER + Regex fallback)
- ğŸ“ˆ Graphical chart visualization (e.g., CBC)
- ğŸ¤– ML-based diagnosis (using both tabular and CNN image models)
- ğŸ’¬ A chatbot interface for Q&A about the uploaded report
- ğŸ“„ Downloadable AI-generated report summary (PDF)

---

## ğŸš€ Features

- ğŸ” **OCR Extraction**: Supports PDF and image formats via Tesseract
- âœ¨ **Text Cleaning & Parsing**: Cleans and structures raw OCR data
- ğŸ§¬ **NER-Based Lab Value Extraction**: Uses HuggingFace-based NER models for high-accuracy recognition
- ğŸ“Š **CBC Graph Generation**: Auto-generates charts from extracted values
- ğŸ’¡ **AI Explanation**: Uses `LLaMA3` or `MedLLaMA2` for rich, simplified medical insights
- ğŸ§  **Dual Diagnosis**:
  - From Lab Values (Rule-Based)
  - From Uploaded Image using CNN (`ConvNeXt-Tiny`) trained on PathMNIST
- ğŸ’¬ **Chatbot**: Ask anything about the medical report and receive context-aware responses
- ğŸ“„ **Exportable PDF Report**

---

## ğŸ› ï¸ Technologies Used

- `Python`, `Streamlit`, `PyTorch`, `Transformers`, `Tesseract OCR`
- `ConvNeXt-Tiny` for medical image-based diagnosis
- `Matplotlib` for chart generation
- HuggingFace Transformers for NER and chatbot models
- PDF processing using `PyMuPDF` and `ReportLab`

---

## ğŸ“¦ Setup Instructions

### ğŸ”— 1. Clone the Repository

git clone https://github.com/coderstale/ai-med-report-explainer.git
cd ai-med-report-explainer

ğŸ§ª 2. Create and Activate a Virtual Environment

python3 -m venv vit_resnet_env
source vit_resnet_env/bin/activate  # or `.\vit_resnet_env\Scripts\activate` on Windows

ğŸ“¥ 3. Install Dependencies

pip install -r requirements.txt

Note: This project uses Git LFS for large models. Make sure Git LFS is installed:

git lfs install
git lfs pull

ğŸ“ 4. Run the App

streamlit run app/app.py


â¸»

ğŸ§  Key Challenges Faced
- OCR Accuracy: Handling noisy data and misread values using regex and NER fallback
- NER Generalisation: Not all lab reports follow standard formatsâ€”had to handle variability and fallbacks
- Pipeline Integration: Seamlessly combining OCR, AI, charts, and PDF generation in one Streamlit interface

â¸»

ğŸ”­ Future Improvements
- âœ… Replace rule-based diagnosis with a trained ML model using tabular lab data
- âœ… Expand chart visualisations to include other panels (e.g., liver/kidney functions)
- ğŸ”¬ Integrate real medical LLMs (e.g., Med-PaLM, ClinicalBERT) with local inference
- ğŸ§¾ Include multiple file upload support (e.g., previous & current reports)
- ğŸ¥ Integration with FHIR-based medical records for real-world applications
- ğŸ“Š Dashboard view for doctors to monitor patient trends

â¸»

ğŸ” For Research

This tool provides a foundation for explainable AI in healthcare, merging vision, NLP, and deep learning. It is ideal for:
- Medical NLP research
- Healthcare analytics projects
- AI explainability use cases
- Educational demonstrations for students and practitioners

â¸»

ğŸ™Œ Credits
- Inspired by the need to make medical lab reports more understandable for patients
- Developed by @coderstale

â¸»

ğŸ“œ License

MIT License
